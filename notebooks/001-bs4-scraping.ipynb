{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup for Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginner Friendly. Useful for pulling data out of HTML and XML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting A Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'https://subslikescript.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_url = f'{root}/movie/Titanic-120338' #url\n",
    "result = requests.get(script_url) # GET request handler\n",
    "content = result.text # result object\n",
    "print(result) #response code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing The Response Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = Soup(content, 'lxml') # Markup language text parser\n",
    "print(soup.prettify()) # pretiffied tree structure of result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding A Single Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = soup.find('article', class_='main-article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = box.find('h1').get_text()\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = box.find('div', class_='full-script').get_text(strip=True, separator=' ')\n",
    "transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Outputs to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/scripts/{title}.txt', 'w') as file:\n",
    "    file.write(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Multiple Links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'{root}/movies' #url\n",
    "result = requests.get(url) # GET request handler\n",
    "content = result.text # result object\n",
    "print(result) #response code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = Soup(content, 'lxml') # Markup language text parser\n",
    "print(soup.prettify()) # pretiffied tree structure of result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = soup.find('article', class_='main-article')\n",
    "\n",
    "links = []\n",
    "for link in box.find_all('a', href=True):\n",
    "    links.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get extract the box from any page\n",
    "def get_box(url):\n",
    "    # getting the html\n",
    "    box = Soup(\n",
    "        requests.get(url).text, 'lxml'\n",
    "    ).find('article', \n",
    "        class_='main-article'\n",
    "    )\n",
    "    return box\n",
    "\n",
    "# to extract transcripts from movie pages \n",
    "def save_transcripts(box):\n",
    "    # extracting specific elements\n",
    "    title = box.find('h1').get_text()\n",
    "    transcript = box.find(\n",
    "        'div', class_='full-script'\n",
    "    ).get_text(strip=True, separator=' ')\n",
    "\n",
    "    # saving to a file\n",
    "    with open(f'data/scripts/{title}.txt', 'w') as file:\n",
    "        file.write(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in links:\n",
    "    url = f'{root}{link}'\n",
    "    movie_box = get_box(url)\n",
    "    print(movie_box.find('h1').get_text())\n",
    "    # save_transcripts(movie_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination = soup.find('ul', class_='pagination')\n",
    "pages = pagination.find_all('li', class_='page-item')\n",
    "last_page = pages[-2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_num in range(2, int(last_page)+1):\n",
    "    page_url = f'{root}/movies?page={page_num}'\n",
    "    list_box = get_box(page_url)\n",
    "    links = [link['href'] for link in list_box.find_all('a', href=True)]\n",
    "    for link in links:\n",
    "        movie_url = f'{root}{link}'\n",
    "        movie_box = get_box(movie_url)\n",
    "        print(movie_box.find('h1').get_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrape-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
